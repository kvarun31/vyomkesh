
class Page_Crawler(object):
    def __init__(self, page):
        self.page = page

    def get_urls(self):
        urls = []
        eq = 0
        start_point = html.find('<a href=',eq)
        while start_point >= 0:
	    eq, url = self._get_url(html,start_point)
            urls.append(url)
    	    start_point = html.find('<a href=',eq)
        return urls

    def _get_url(self, start_point):
        start_quote = html.find('"',start_point)
        end_quote = html.find('"',start_quote+1)
        url = html[start_quote+1:end_quote]
        return (end_quote,url)

urls = get_urls(page)
for url in urls:
    print url
